<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Causal Criticality of Layers in Chain-of-Thought | bluee :)</title>
<meta name="keywords" content="Chain-of-Thought, CoT, Interpretability, LLM, AI, Qwen2">
<meta name="description" content="Late layers matter. A probe into Qwen2-1.5B with activation patching, a logit lens, and targeted ablations found that the mid-to-late layers — especially around layer 24 — often synthesize intermediate chain-of-thought steps into the final answer.">
<meta name="author" content="Barshan Mondal">
<link rel="canonical" href="https://barshan.is-a.dev/posts/2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://barshan.is-a.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://barshan.is-a.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://barshan.is-a.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://barshan.is-a.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://barshan.is-a.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Causal Criticality of Layers in Chain-of-Thought" />
<meta property="og:description" content="Late layers matter. A probe into Qwen2-1.5B with activation patching, a logit lens, and targeted ablations found that the mid-to-late layers — especially around layer 24 — often synthesize intermediate chain-of-thought steps into the final answer." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://barshan.is-a.dev/posts/2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-12-14T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-12-14T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Causal Criticality of Layers in Chain-of-Thought"/>
<meta name="twitter:description" content="Late layers matter. A probe into Qwen2-1.5B with activation patching, a logit lens, and targeted ablations found that the mid-to-late layers — especially around layer 24 — often synthesize intermediate chain-of-thought steps into the final answer."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://barshan.is-a.dev/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Causal Criticality of Layers in Chain-of-Thought",
      "item": "https://barshan.is-a.dev/posts/2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Causal Criticality of Layers in Chain-of-Thought",
  "name": "Causal Criticality of Layers in Chain-of-Thought",
  "description": "Late layers matter. A probe into Qwen2-1.5B with activation patching, a logit lens, and targeted ablations found that the mid-to-late layers — especially around layer 24 — often synthesize intermediate chain-of-thought steps into the final answer.",
  "keywords": [
    "Chain-of-Thought", "CoT", "Interpretability", "LLM", "AI", "Qwen2"
  ],
  "articleBody": "Identifying the specific components responsible for reasoning in Large Language Models is a key step towards understanding (and improving) them. My recent research addresses a specific question: Which components are causally critical for correct chain-of-thought (CoT) reasoning?\nUsing Qwen2-1.5B as a testbed, I hypothesized that later layers are more crucial for synthesizing intermediate CoT steps into the final answer, while earlier layers perform foundational computations. To test this, I applied activation patching on GSM8K-style math problems where the model exhibits variable CoT performance, aiming to isolate layer-specific causal contributions.\nKey Findings: The TL;DR Late Layers Matter: Patching into layer 24 produced the strongest causal recovery of correct answers (avg logit improvement +1.48), while earlier layers often introduced interference. The “Crystallization” Point: Logit lens analysis shows that probability for the correct token often spikes in mid-to-late layers (16-24) at specific token positions, suggesting a “resolution” phase in the reasoning chain. Critical Subcomponents: Zero-ablating the MLP in layer 24 degraded performance, and specific neurons (like Neuron 609) showed clear oscillatory patterns on math tokens, hinting at specialized symbolic processing roles. Setup and Motivation Chain-of-thought reasoning enhances LLM performance on complex tasks, but its internal mechanisms remain opaque. Inspired by works like Arditi et al. on single-direction mediation and sample projects on model diffing, I focused on the causal criticality of layers during CoT. Qwen2-1.5B was chosen for its tractability and baseline CoT capabilities.\nI used NNsight for tracing, with GSM8K problems filtered for cases where the model generates CoT but errs. My hypothesis was a progression from computation to integration across the model’s 28 layers.\nDetailed Methods Prompts \u0026 Problems: I selected 6 GSM8K-style problems (e.g., “Solve x^2 + 5x + 6 = 0”) where the model often stumbles. Prompts used the simple template Q: {question}\\nA: to elicit natural CoT. Baselines: Noisy Clean Run: Added Gaussian noise (σ=2.0) to layer 0 activations to corrupt early reasoning. This effectively “broke” the chain. Base Run: A normal forward pass (often yielding wrong answers in the selected set), caching activations at source layers 16, 20, and 24. Patching Intervention: In the noisy run, I restored residuals from the base run into target layer 24, restricted to the last 50 tokens (late CoT positions). Metric: Δlogit = patched_logit - clean_correct_logit. Logit Lens \u0026 Ablation: Projected residual streams to logits across all layers (0-27) to track token probabilities. Zero-ablated MLP outputs in layer 24 to test subcomponent necessity. Analyzed specific neuron activations (e.g., Neuron 609). Results and Analysis 1. Patching: The Rescue Effect of Layer 24 Patching effects varied significantly by source layer.\nLayer 16: Average logit improvement of -2.23. This was often harmful, suggesting that early/mid-layer residuals are not interchangeable and interventions here can cause interference. Layer 20: Moderate positive effect (+1.33). Layer 24 (Control): Strongest improvement (+1.48). This implies that late-layer “resolution” circuits are critical for the final output. In specific cases (like the quadratic equation problem), patching layer 24 improved the logit from ~-5.2 to ~-0.5, effectively restoring the reasoning chain.\n2. Ablation: The Role of the MLP To dig deeper, I zero-ablated the MLP output in layer 24 for the late positions. This usually resulted in a degradation of the correct logit (avg -0.20), confirming that the MLP block in this layer is actively contributing to the correct solution, not just passing information through.\n3. Logit Lens: Visualizing Belief Evolution The logit lens allows us to see what the model “believes” at every layer and token position. I aggregated data from ~100 CoT generations.\nCoT Length \u0026 Accuracy: Most CoT sequences clustered around 500 tokens. Interestingly, there was a slight negative correlation between length and accuracy—longer CoTs were slightly less likely to be correct.\nProbability Heatmaps: The heatmaps reveal “vertical bands” where the probability of the wrong or correct answer spikes.\nWrong Token: Spikes in early-mid layers (0-12) at positions 50-150. Correct Token: Spikes in mid-late layers (12-24) at positions 100-300. This visualizes the “crystallization” of the correct answer in the later layers.\n(Note the dark vertical bands indicating high probability regions across layers)\n4. Neuron Analysis: The Math Operator I identified specific neurons that seemed specialized. Neuron 609 in Layer 24, for instance, activates strongly on math formatting and operators (e.g., =, *, numbers). Its activation pattern oscillates in sync with the generation of mathematical steps.\nDiscussion \u0026 Future Directions The findings suggest a “reasoning pipeline” where late layers act as bottlenecks for CoT correctness. The logit lens analysis complements the patching results by showing how position-layer interactions evolve—errors often appear early, while resolution happens late.\nLimitations:\nSmall N: The core patching was done on 6 problems. Model Specifics: Qwen2-1.5B is small and might not perfectly represent the reasoning circuits of larger models like DeepSeek-R1. Variable CoT Lengths: Averaging required truncation, which introduces some bias. Learnings: Activation patching is a powerful tool for causal tracing but is highly sensitive to noise levels. Over-correction can mask subtle effects, highlighting the need for calibrated interventions.\nIn the future, I’d like to:\nTest on true “reasoning-tuned” models. Integrate Sparse Autoencoders (SAEs) for feature-level insights. Correlate the Logit Lens probabilities directly with patching improvements. Epistemic Status *This was a quick exploratory sweep (approx. 1 week of research) using a small sample size. Results are preliminary. All code is reproducible in the associated notebook/repo.\nFor a detailed report check out my doc Doc.\n",
  "wordCount" : "886",
  "inLanguage": "en",
  "datePublished": "2025-12-14T00:00:00Z",
  "dateModified": "2025-12-14T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Barshan Mondal"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://barshan.is-a.dev/posts/2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "bluee :)",
    "logo": {
      "@type": "ImageObject",
      "url": "https://barshan.is-a.dev/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://barshan.is-a.dev/" accesskey="h" title="bluee :) (Alt + H)">bluee :)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://barshan.is-a.dev/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://barshan.is-a.dev/">Home</a>&nbsp;»&nbsp;<a href="https://barshan.is-a.dev/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Causal Criticality of Layers in Chain-of-Thought
    </h1>
    <div class="post-meta"><span title='2025-12-14 00:00:00 +0000 UTC'>December 14, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Barshan Mondal

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#key-findings-the-tldr" aria-label="Key Findings: The TL;DR">Key Findings: The TL;DR</a></li>
                <li>
                    <a href="#setup-and-motivation" aria-label="Setup and Motivation">Setup and Motivation</a><ul>
                        
                <li>
                    <a href="#detailed-methods" aria-label="Detailed Methods">Detailed Methods</a></li></ul>
                </li>
                <li>
                    <a href="#results-and-analysis" aria-label="Results and Analysis">Results and Analysis</a><ul>
                        
                <li>
                    <a href="#1-patching-the-rescue-effect-of-layer-24" aria-label="1. Patching: The Rescue Effect of Layer 24">1. Patching: The Rescue Effect of Layer 24</a></li>
                <li>
                    <a href="#2-ablation-the-role-of-the-mlp" aria-label="2. Ablation: The Role of the MLP">2. Ablation: The Role of the MLP</a></li>
                <li>
                    <a href="#3-logit-lens-visualizing-belief-evolution" aria-label="3. Logit Lens: Visualizing Belief Evolution">3. Logit Lens: Visualizing Belief Evolution</a></li>
                <li>
                    <a href="#4-neuron-analysis-the-math-operator" aria-label="4. Neuron Analysis: The Math Operator">4. Neuron Analysis: The Math Operator</a></li></ul>
                </li>
                <li>
                    <a href="#discussion--future-directions" aria-label="Discussion &amp; Future Directions">Discussion &amp; Future Directions</a></li>
                <li>
                    <a href="#epistemic-status" aria-label="Epistemic Status">Epistemic Status</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Identifying the specific components responsible for reasoning in Large Language Models is a key step towards understanding (and improving) them. My recent research addresses a specific question: <strong>Which components are causally critical for correct chain-of-thought (CoT) reasoning?</strong></p>
<p>Using <strong>Qwen2-1.5B</strong> as a testbed, I hypothesized that later layers are more crucial for synthesizing intermediate CoT steps into the final answer, while earlier layers perform foundational computations. To test this, I applied activation patching on GSM8K-style math problems where the model exhibits variable CoT performance, aiming to isolate layer-specific causal contributions.</p>
<h2 id="key-findings-the-tldr">Key Findings: The TL;DR<a hidden class="anchor" aria-hidden="true" href="#key-findings-the-tldr">#</a></h2>
<ul>
<li><strong>Late Layers Matter:</strong> Patching into layer 24 produced the strongest causal recovery of correct answers (avg logit improvement +1.48), while earlier layers often introduced interference.</li>
<li><strong>The &ldquo;Crystallization&rdquo; Point:</strong> Logit lens analysis shows that probability for the correct token often spikes in mid-to-late layers (16-24) at specific token positions, suggesting a &ldquo;resolution&rdquo; phase in the reasoning chain.</li>
<li><strong>Critical Subcomponents:</strong> Zero-ablating the MLP in layer 24 degraded performance, and specific neurons (like <strong>Neuron 609</strong>) showed clear oscillatory patterns on math tokens, hinting at specialized symbolic processing roles.</li>
</ul>
<hr>
<h2 id="setup-and-motivation">Setup and Motivation<a hidden class="anchor" aria-hidden="true" href="#setup-and-motivation">#</a></h2>
<p>Chain-of-thought reasoning enhances LLM performance on complex tasks, but its internal mechanisms remain opaque. Inspired by works like Arditi et al. on single-direction mediation and sample projects on model diffing, I focused on the <strong>causal criticality</strong> of layers during CoT. Qwen2-1.5B was chosen for its tractability and baseline CoT capabilities.</p>
<p>I used <code>NNsight</code> for tracing, with GSM8K problems filtered for cases where the model generates CoT but errs. My hypothesis was a progression from computation to integration across the model&rsquo;s 28 layers.</p>
<h3 id="detailed-methods">Detailed Methods<a hidden class="anchor" aria-hidden="true" href="#detailed-methods">#</a></h3>
<ol>
<li><strong>Prompts &amp; Problems:</strong> I selected 6 GSM8K-style problems (e.g., &ldquo;Solve x^2 + 5x + 6 = 0&rdquo;) where the model often stumbles. Prompts used the simple template <code>Q: {question}\nA:</code> to elicit natural CoT.</li>
<li><strong>Baselines:</strong>
<ul>
<li><strong>Noisy Clean Run:</strong> Added Gaussian noise (σ=2.0) to layer 0 activations to corrupt early reasoning. This effectively &ldquo;broke&rdquo; the chain.</li>
<li><strong>Base Run:</strong> A normal forward pass (often yielding wrong answers in the selected set), caching activations at source layers 16, 20, and 24.</li>
</ul>
</li>
<li><strong>Patching Intervention:</strong> In the noisy run, I restored residuals from the base run into <strong>target layer 24</strong>, restricted to the last 50 tokens (late CoT positions).
<ul>
<li><em>Metric:</em> Δlogit = patched_logit - clean_correct_logit.</li>
</ul>
</li>
<li><strong>Logit Lens &amp; Ablation:</strong>
<ul>
<li>Projected residual streams to logits across all layers (0-27) to track token probabilities.</li>
<li>Zero-ablated MLP outputs in layer 24 to test subcomponent necessity.</li>
<li>Analyzed specific neuron activations (e.g., Neuron 609).</li>
</ul>
</li>
</ol>
<hr>
<h2 id="results-and-analysis">Results and Analysis<a hidden class="anchor" aria-hidden="true" href="#results-and-analysis">#</a></h2>
<h3 id="1-patching-the-rescue-effect-of-layer-24">1. Patching: The Rescue Effect of Layer 24<a hidden class="anchor" aria-hidden="true" href="#1-patching-the-rescue-effect-of-layer-24">#</a></h3>
<p>Patching effects varied significantly by source layer.</p>
<ul>
<li><strong>Layer 16:</strong> Average logit improvement of <strong>-2.23</strong>. This was often harmful, suggesting that early/mid-layer residuals are not interchangeable and interventions here can cause interference.</li>
<li><strong>Layer 20:</strong> Moderate positive effect (+1.33).</li>
<li><strong>Layer 24 (Control):</strong> Strongest improvement (<strong>+1.48</strong>). This implies that late-layer &ldquo;resolution&rdquo; circuits are critical for the final output.</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/avg_improvement_in_correct_token_logit.png" alt="Fig 4: Average Improvement in Correct Token Logit (Residual Patching into Layer 24)."  />
</p>
<p>In specific cases (like the quadratic equation problem), patching layer 24 improved the logit from ~-5.2 to ~-0.5, effectively restoring the reasoning chain.</p>
<h3 id="2-ablation-the-role-of-the-mlp">2. Ablation: The Role of the MLP<a hidden class="anchor" aria-hidden="true" href="#2-ablation-the-role-of-the-mlp">#</a></h3>
<p>To dig deeper, I zero-ablated the MLP output in layer 24 for the late positions. This usually resulted in a degradation of the correct logit (avg <strong>-0.20</strong>), confirming that the MLP block in this layer is actively contributing to the correct solution, not just passing information through.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/Effect%20of%20zero-ablating%20MLP%20Output%20in%20layer%2024.png" alt="Fig 3: Effect of Zero-Ablating MLP Output in Layer 24."  />
</p>
<h3 id="3-logit-lens-visualizing-belief-evolution">3. Logit Lens: Visualizing Belief Evolution<a hidden class="anchor" aria-hidden="true" href="#3-logit-lens-visualizing-belief-evolution">#</a></h3>
<p>The logit lens allows us to see what the model &ldquo;believes&rdquo; at every layer and token position. I aggregated data from ~100 CoT generations.</p>
<p><strong>CoT Length &amp; Accuracy:</strong>
Most CoT sequences clustered around 500 tokens. Interestingly, there was a slight negative correlation between length and accuracy—longer CoTs were slightly less likely to be correct.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/COT%20lengths%20before%20finetuning%20for%2080%20problems.png" alt="Fig 1: Distribution of CoT Lengths"  />
</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/Cot_length%20vs%20Acuracy_80%20problems_%20before%20finetuning.png" alt="Fig 2: CoT Length vs Accuracy"  />
</p>
<p><strong>Probability Heatmaps:</strong>
The heatmaps reveal &ldquo;vertical bands&rdquo; where the probability of the <em>wrong</em> or <em>correct</em> answer spikes.</p>
<ul>
<li><strong>Wrong Token:</strong> Spikes in early-mid layers (0-12) at positions 50-150.</li>
<li><strong>Correct Token:</strong> Spikes in mid-late layers (12-24) at positions 100-300.</li>
</ul>
<p>This visualizes the &ldquo;crystallization&rdquo; of the correct answer in the later layers.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/Logit%20Lens%20Probability%20Heatmap_wrong%20and%20right%20answer.png" alt="Fig 6/7: Average Logit Lens Probability Heatmap"  />
</p>
<p><em>(Note the dark vertical bands indicating high probability regions across layers)</em></p>
<h3 id="4-neuron-analysis-the-math-operator">4. Neuron Analysis: The Math Operator<a hidden class="anchor" aria-hidden="true" href="#4-neuron-analysis-the-math-operator">#</a></h3>
<p>I identified specific neurons that seemed specialized. <strong>Neuron 609 in Layer 24</strong>, for instance, activates strongly on math formatting and operators (e.g., <code>=</code>, <code>*</code>, numbers). Its activation pattern oscillates in sync with the generation of mathematical steps.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/blueee04/blog/refs/heads/main/content/images/2025-12-14-Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20Reasoning/Neuron%20609%20activation%20pattern.png" alt="Fig 5: Neuron 609 Activation Pattern"  />
</p>
<hr>
<h2 id="discussion--future-directions">Discussion &amp; Future Directions<a hidden class="anchor" aria-hidden="true" href="#discussion--future-directions">#</a></h2>
<p>The findings suggest a <strong>&ldquo;reasoning pipeline&rdquo;</strong> where late layers act as bottlenecks for CoT correctness. The logit lens analysis complements the patching results by showing how position-layer interactions evolve—errors often appear early, while resolution happens late.</p>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Small N:</strong> The core patching was done on 6 problems.</li>
<li><strong>Model Specifics:</strong> Qwen2-1.5B is small and might not perfectly represent the reasoning circuits of larger models like DeepSeek-R1.</li>
<li><strong>Variable CoT Lengths:</strong> Averaging required truncation, which introduces some bias.</li>
</ul>
<p><strong>Learnings:</strong>
Activation patching is a powerful tool for causal tracing but is highly sensitive to noise levels. Over-correction can mask subtle effects, highlighting the need for calibrated interventions.</p>
<p>In the future, I&rsquo;d like to:</p>
<ul>
<li>Test on true &ldquo;reasoning-tuned&rdquo; models.</li>
<li>Integrate Sparse Autoencoders (SAEs) for feature-level insights.</li>
<li>Correlate the Logit Lens probabilities directly with patching improvements.</li>
</ul>
<h2 id="epistemic-status">Epistemic Status<a hidden class="anchor" aria-hidden="true" href="#epistemic-status">#</a></h2>
<p>*This was a quick exploratory sweep (approx. 1 week of research) using a small sample size. Results are preliminary. All code is reproducible in the associated <a href="https://colab.research.google.com/drive/1b5nOLR4duhmBtOsHmwalYdmzXS-ux5j7?usp=sharing">notebook/repo</a>.</p>
<p>For a detailed report check out my doc <a href="https://docs.google.com/document/d/1AG7rOnjeIDMCd4-TDX7oDWUy0lE7IhWAR6XQ8U0_i5k/edit?tab=t.0">Doc</a>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://barshan.is-a.dev/tags/chain-of-thought/">Chain-of-Thought</a></li>
      <li><a href="https://barshan.is-a.dev/tags/cot/">CoT</a></li>
      <li><a href="https://barshan.is-a.dev/tags/interpretability/">Interpretability</a></li>
      <li><a href="https://barshan.is-a.dev/tags/llm/">LLM</a></li>
      <li><a href="https://barshan.is-a.dev/tags/ai/">AI</a></li>
      <li><a href="https://barshan.is-a.dev/tags/qwen2/">Qwen2</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://barshan.is-a.dev/posts/2025-11-19-transfomers/">
    <span class="title">Next »</span>
    <br>
    <span>Before We Hop Onto TRANSFORMERS </span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on x"
            href="https://x.com/intent/tweet/?text=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought&amp;url=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f&amp;hashtags=Chain-of-Thought%2cCoT%2cInterpretability%2cLLM%2cAI%2cQwen2">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f&amp;title=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought&amp;summary=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought&amp;source=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f&title=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on whatsapp"
            href="https://api.whatsapp.com/send?text=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought%20-%20https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on telegram"
            href="https://telegram.me/share/url?text=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought&amp;url=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Causal Criticality of Layers in Chain-of-Thought on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Causal%20Criticality%20of%20Layers%20in%20Chain-of-Thought&u=https%3a%2f%2fbarshan.is-a.dev%2fposts%2f2025-12-14-causal-criticality-of-layers-in-chain-of-thought-reasoning%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2026 <a href="https://barshan.is-a.dev/">bluee :)</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
